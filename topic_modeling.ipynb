{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_raw = pd.read_csv(\"awards_data_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boilerplate = (\n",
    "    \"This award reflects NSF's statutory mission and has been deemed worthy of support \"\n",
    "    \"through evaluation using the Foundation's intellectual merit and broader impacts review criteria.\"\n",
    ")\n",
    "\n",
    "awards_raw[\"Abstract\"] = awards_raw[\"Abstract\"].str.replace(boilerplate, \"\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_raw.to_csv(\"awards_data_noboiler.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural Topic Modeling\n",
    "\n",
    "Using other variables to help make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning for STM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_raw['Abstract'] = awards_raw['Abstract'].str.lower()\n",
    "awards_raw['Title'] = awards_raw['Title'].str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am going to concatenate the Title and Abstract columns\n",
    "awards_raw['text'] = awards_raw['Title'] + \". \" + awards_raw['Abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     157500, 169000, 915000\n",
       "1     113900, 157500, 915000\n",
       "2     113900, 727500, 198600\n",
       "3                     113900\n",
       "4             072Y00, 808500\n",
       "5                     178800\n",
       "6                     806000\n",
       "7             117100, 613300\n",
       "8                     808500\n",
       "9                     177100\n",
       "10                    177300\n",
       "11                    741200\n",
       "12                    026Y00\n",
       "13            745900, 772700\n",
       "14                    177500\n",
       "15                    162000\n",
       "16                    140300\n",
       "17            132100, 139700\n",
       "18                    760500\n",
       "19            157200, 157500\n",
       "Name: ProgramElementCode(s), dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "awards_raw['ProgramElementCode(s)'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            9150, 9250\n",
       "1                                            9150, 9250\n",
       "2                                      8007, 9250, 8091\n",
       "3                                                  9250\n",
       "4     9251, 9102, 9178, 9231, 116E, 067E, 073E, 8043...\n",
       "5                          082E, 083E, 084E, 9146, MANU\n",
       "6                                            7924, 7434\n",
       "7                                1228, 7744, 9178, 9251\n",
       "8                          067E, 068E, 8024, 8043, 9102\n",
       "9                                                   NaN\n",
       "10                                     7504, 8037, 8091\n",
       "11                                     1032, 9178, SMET\n",
       "12                                           7495, 8228\n",
       "13                                           5911, 5977\n",
       "14                               7237, 8396, 8611, 8990\n",
       "15                                                 9150\n",
       "16                                           1045, 9251\n",
       "17                                     1045, 1321, 9179\n",
       "18                               1390, 9179, EGCH, SMET\n",
       "19                                                 1045\n",
       "Name: ProgramReferenceCode(s), dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awards_raw['ProgramReferenceCode(s)'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue here, multiple codes. I will start by just using the first code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_raw['ProgramElementMain'] = awards_raw['ProgramElementCode(s)'].str.split(',').str[0].str.strip()\n",
    "awards_raw['ProgramReferenceMain'] = awards_raw['ProgramReferenceCode(s)'].str.split(',').str[0].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "awards_raw['program_label'] = LabelEncoder().fit_transform(awards_raw['ProgramElementMain'].fillna(\"unknown\"))\n",
    "awards_raw['reference_label'] = LabelEncoder().fit_transform(awards_raw['ProgramReferenceMain'].fillna(\"unknown\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized text for bag of words\n",
    "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessingStopwords\n",
    "\n",
    "awards_raw['clean_text'] = awards_raw['Abstract']\n",
    "\n",
    "qt = WhiteSpacePreprocessingStopwords(awards_raw['clean_text'].tolist())\n",
    "preprocessed_docs = qt.preprocess()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardNumber</th>\n",
       "      <th>Title</th>\n",
       "      <th>NSFOrganization</th>\n",
       "      <th>Program(s)</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>LastAmendmentDate</th>\n",
       "      <th>PrincipalInvestigator</th>\n",
       "      <th>State</th>\n",
       "      <th>Organization</th>\n",
       "      <th>AwardInstrument</th>\n",
       "      <th>...</th>\n",
       "      <th>ProgramReferenceCode(s)</th>\n",
       "      <th>ARRAAmount</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Year</th>\n",
       "      <th>text</th>\n",
       "      <th>ProgramElementMain</th>\n",
       "      <th>ProgramReferenceMain</th>\n",
       "      <th>program_label</th>\n",
       "      <th>reference_label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1560196</td>\n",
       "      <td>reu site: earth science on volcanic islands</td>\n",
       "      <td>EAR</td>\n",
       "      <td>EDUCATION AND HUMAN RESOURCES, EDUCATION/HUMAN...</td>\n",
       "      <td>10/01/2016</td>\n",
       "      <td>07/17/2018</td>\n",
       "      <td>Paul Wessel</td>\n",
       "      <td>HI</td>\n",
       "      <td>University of Hawaii</td>\n",
       "      <td>Continuing Grant</td>\n",
       "      <td>...</td>\n",
       "      <td>9150, 9250</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>earth science on volcanic island esvi be a new...</td>\n",
       "      <td>2016</td>\n",
       "      <td>reu site: earth science on volcanic islands. e...</td>\n",
       "      <td>157500</td>\n",
       "      <td>9150</td>\n",
       "      <td>217</td>\n",
       "      <td>592</td>\n",
       "      <td>earth science on volcanic island esvi be a new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1560048</td>\n",
       "      <td>reu site:  sustainable river (remediating inva...</td>\n",
       "      <td>DBI</td>\n",
       "      <td>RSCH EXPER FOR UNDERGRAD SITES, EDUCATION AND ...</td>\n",
       "      <td>09/15/2016</td>\n",
       "      <td>11/19/2017</td>\n",
       "      <td>Meghann Jarchow</td>\n",
       "      <td>SD</td>\n",
       "      <td>University of South Dakota Main Campus</td>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>...</td>\n",
       "      <td>9150, 9250</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>reu site sustainable river remediating invasiv...</td>\n",
       "      <td>2016</td>\n",
       "      <td>reu site:  sustainable river (remediating inva...</td>\n",
       "      <td>113900</td>\n",
       "      <td>9150</td>\n",
       "      <td>101</td>\n",
       "      <td>592</td>\n",
       "      <td>reu site sustainable river remediating invasiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1560200</td>\n",
       "      <td>reu site: integrated science for society (is2)</td>\n",
       "      <td>DBI</td>\n",
       "      <td>RSCH EXPER FOR UNDERGRAD SITES, Cross-BIO Acti...</td>\n",
       "      <td>09/15/2016</td>\n",
       "      <td>08/01/2018</td>\n",
       "      <td>Kenneth Burch</td>\n",
       "      <td>MA</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>...</td>\n",
       "      <td>8007, 9250, 8091</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>this reu site award to boston college locate i...</td>\n",
       "      <td>2016</td>\n",
       "      <td>reu site: integrated science for society (is2)...</td>\n",
       "      <td>113900</td>\n",
       "      <td>8007</td>\n",
       "      <td>101</td>\n",
       "      <td>511</td>\n",
       "      <td>this reu site award to boston college locate i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1560169</td>\n",
       "      <td>reu site: utilizing plants for innovative rese...</td>\n",
       "      <td>DBI</td>\n",
       "      <td>RSCH EXPER FOR UNDERGRAD SITES</td>\n",
       "      <td>09/15/2016</td>\n",
       "      <td>03/01/2016</td>\n",
       "      <td>Lihua Wang</td>\n",
       "      <td>MI</td>\n",
       "      <td>Kettering University</td>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>...</td>\n",
       "      <td>9250</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>this reu site award to kettering university lo...</td>\n",
       "      <td>2016</td>\n",
       "      <td>reu site: utilizing plants for innovative rese...</td>\n",
       "      <td>113900</td>\n",
       "      <td>9250</td>\n",
       "      <td>101</td>\n",
       "      <td>610</td>\n",
       "      <td>this reu site award to kettering university lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1563408</td>\n",
       "      <td>hidden costs of decomposition: the need for fi...</td>\n",
       "      <td>CMMI</td>\n",
       "      <td>EDSE-Engineering Design and Sy, SYS-Systems Sc...</td>\n",
       "      <td>09/01/2016</td>\n",
       "      <td>05/03/2018</td>\n",
       "      <td>Erica Gralla</td>\n",
       "      <td>DC</td>\n",
       "      <td>George Washington University</td>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>...</td>\n",
       "      <td>9251, 9102, 9178, 9231, 116E, 067E, 073E, 8043...</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>engineered system be become increasingly compl...</td>\n",
       "      <td>2016</td>\n",
       "      <td>hidden costs of decomposition: the need for fi...</td>\n",
       "      <td>072Y00</td>\n",
       "      <td>9251</td>\n",
       "      <td>56</td>\n",
       "      <td>611</td>\n",
       "      <td>engineered system be become increasingly compl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardNumber                                              Title  \\\n",
       "0      1560196        reu site: earth science on volcanic islands   \n",
       "1      1560048  reu site:  sustainable river (remediating inva...   \n",
       "2      1560200     reu site: integrated science for society (is2)   \n",
       "3      1560169  reu site: utilizing plants for innovative rese...   \n",
       "4      1563408  hidden costs of decomposition: the need for fi...   \n",
       "\n",
       "  NSFOrganization                                         Program(s)  \\\n",
       "0             EAR  EDUCATION AND HUMAN RESOURCES, EDUCATION/HUMAN...   \n",
       "1             DBI  RSCH EXPER FOR UNDERGRAD SITES, EDUCATION AND ...   \n",
       "2             DBI  RSCH EXPER FOR UNDERGRAD SITES, Cross-BIO Acti...   \n",
       "3             DBI                     RSCH EXPER FOR UNDERGRAD SITES   \n",
       "4            CMMI  EDSE-Engineering Design and Sy, SYS-Systems Sc...   \n",
       "\n",
       "    StartDate LastAmendmentDate PrincipalInvestigator State  \\\n",
       "0  10/01/2016        07/17/2018           Paul Wessel    HI   \n",
       "1  09/15/2016        11/19/2017       Meghann Jarchow    SD   \n",
       "2  09/15/2016        08/01/2018         Kenneth Burch    MA   \n",
       "3  09/15/2016        03/01/2016            Lihua Wang    MI   \n",
       "4  09/01/2016        05/03/2018          Erica Gralla    DC   \n",
       "\n",
       "                             Organization   AwardInstrument  ...  \\\n",
       "0                    University of Hawaii  Continuing Grant  ...   \n",
       "1  University of South Dakota Main Campus    Standard Grant  ...   \n",
       "2                          Boston College    Standard Grant  ...   \n",
       "3                    Kettering University    Standard Grant  ...   \n",
       "4            George Washington University    Standard Grant  ...   \n",
       "\n",
       "                             ProgramReferenceCode(s) ARRAAmount  \\\n",
       "0                                         9150, 9250      $0.00   \n",
       "1                                         9150, 9250      $0.00   \n",
       "2                                   8007, 9250, 8091      $0.00   \n",
       "3                                               9250      $0.00   \n",
       "4  9251, 9102, 9178, 9231, 116E, 067E, 073E, 8043...      $0.00   \n",
       "\n",
       "                                            Abstract  Year  \\\n",
       "0  earth science on volcanic island esvi be a new...  2016   \n",
       "1  reu site sustainable river remediating invasiv...  2016   \n",
       "2  this reu site award to boston college locate i...  2016   \n",
       "3  this reu site award to kettering university lo...  2016   \n",
       "4  engineered system be become increasingly compl...  2016   \n",
       "\n",
       "                                                text ProgramElementMain  \\\n",
       "0  reu site: earth science on volcanic islands. e...             157500   \n",
       "1  reu site:  sustainable river (remediating inva...             113900   \n",
       "2  reu site: integrated science for society (is2)...             113900   \n",
       "3  reu site: utilizing plants for innovative rese...             113900   \n",
       "4  hidden costs of decomposition: the need for fi...             072Y00   \n",
       "\n",
       "  ProgramReferenceMain program_label reference_label  \\\n",
       "0                 9150           217             592   \n",
       "1                 9150           101             592   \n",
       "2                 8007           101             511   \n",
       "3                 9250           101             610   \n",
       "4                 9251            56             611   \n",
       "\n",
       "                                          clean_text  \n",
       "0  earth science on volcanic island esvi be a new...  \n",
       "1  reu site sustainable river remediating invasiv...  \n",
       "2  this reu site award to boston college locate i...  \n",
       "3  this reu site award to kettering university lo...  \n",
       "4  engineered system be become increasingly compl...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awards_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15290 entries, 0 to 15289\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   AwardNumber              15290 non-null  int64  \n",
      " 1   Title                    15290 non-null  object \n",
      " 2   NSFOrganization          15290 non-null  object \n",
      " 3   Program(s)               15267 non-null  object \n",
      " 4   StartDate                15290 non-null  object \n",
      " 5   LastAmendmentDate        15290 non-null  object \n",
      " 6   PrincipalInvestigator    15289 non-null  object \n",
      " 7   State                    15280 non-null  object \n",
      " 8   Organization             15290 non-null  object \n",
      " 9   AwardInstrument          15290 non-null  object \n",
      " 10  ProgramManager           15290 non-null  object \n",
      " 11  EndDate                  15290 non-null  object \n",
      " 12  AwardedAmountToDate      15290 non-null  object \n",
      " 13  Co-PIName(s)             4835 non-null   object \n",
      " 14  PIEmailAddress           15068 non-null  object \n",
      " 15  OrganizationStreet       15070 non-null  object \n",
      " 16  OrganizationCity         15290 non-null  object \n",
      " 17  OrganizationState        15280 non-null  object \n",
      " 18  OrganizationZip          15287 non-null  object \n",
      " 19  OrganizationPhone        15070 non-null  float64\n",
      " 20  NSFDirectorate           15290 non-null  object \n",
      " 21  ProgramElementCode(s)    15267 non-null  object \n",
      " 22  ProgramReferenceCode(s)  13838 non-null  object \n",
      " 23  ARRAAmount               15290 non-null  object \n",
      " 24  Abstract                 15290 non-null  object \n",
      " 25  Year                     15290 non-null  int64  \n",
      " 26  text                     15290 non-null  object \n",
      " 27  ProgramElementMain       15267 non-null  object \n",
      " 28  ProgramReferenceMain     13838 non-null  object \n",
      " 29  program_label            15290 non-null  int64  \n",
      " 30  reference_label          15290 non-null  int64  \n",
      " 31  clean_text               15290 non-null  object \n",
      "dtypes: float64(1), int64(4), object(27)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: DeprecationWarning: invalid escape sequence \\$\n",
      "<>:3: DeprecationWarning: invalid escape sequence \\$\n",
      "/var/folders/ms/yvnygwhs3jq6kw556d3s72lc0000gn/T/ipykernel_48633/917461660.py:3: DeprecationWarning: invalid escape sequence \\$\n",
      "  .replace('[\\$,]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "awards_raw['AwardedAmountToDate'] = (\n",
    "    awards_raw['AwardedAmountToDate']\n",
    "    .replace('[\\$,]', '', regex=True)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "awards_raw['AwardedAmountToDate'] = pd.to_numeric(awards_raw['AwardedAmountToDate'], errors='coerce')\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "awards_raw['Award_scaled'] = scaler.fit_transform(awards_raw[['AwardedAmountToDate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardNumber</th>\n",
       "      <th>Title</th>\n",
       "      <th>NSFOrganization</th>\n",
       "      <th>Program(s)</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>LastAmendmentDate</th>\n",
       "      <th>PrincipalInvestigator</th>\n",
       "      <th>State</th>\n",
       "      <th>Organization</th>\n",
       "      <th>AwardInstrument</th>\n",
       "      <th>...</th>\n",
       "      <th>ARRAAmount</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Year</th>\n",
       "      <th>text</th>\n",
       "      <th>ProgramElementMain</th>\n",
       "      <th>ProgramReferenceMain</th>\n",
       "      <th>program_label</th>\n",
       "      <th>reference_label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Award_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1560196</td>\n",
       "      <td>reu site: earth science on volcanic islands</td>\n",
       "      <td>EAR</td>\n",
       "      <td>EDUCATION AND HUMAN RESOURCES, EDUCATION/HUMAN...</td>\n",
       "      <td>10/01/2016</td>\n",
       "      <td>07/17/2018</td>\n",
       "      <td>Paul Wessel</td>\n",
       "      <td>HI</td>\n",
       "      <td>University of Hawaii</td>\n",
       "      <td>Continuing Grant</td>\n",
       "      <td>...</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>earth science on volcanic island esvi be a new...</td>\n",
       "      <td>2016</td>\n",
       "      <td>reu site: earth science on volcanic islands. e...</td>\n",
       "      <td>157500</td>\n",
       "      <td>9150</td>\n",
       "      <td>217</td>\n",
       "      <td>592</td>\n",
       "      <td>earth science on volcanic island esvi be a new...</td>\n",
       "      <td>0.058767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1560048</td>\n",
       "      <td>reu site:  sustainable river (remediating inva...</td>\n",
       "      <td>DBI</td>\n",
       "      <td>RSCH EXPER FOR UNDERGRAD SITES, EDUCATION AND ...</td>\n",
       "      <td>09/15/2016</td>\n",
       "      <td>11/19/2017</td>\n",
       "      <td>Meghann Jarchow</td>\n",
       "      <td>SD</td>\n",
       "      <td>University of South Dakota Main Campus</td>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>...</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>reu site sustainable river remediating invasiv...</td>\n",
       "      <td>2016</td>\n",
       "      <td>reu site:  sustainable river (remediating inva...</td>\n",
       "      <td>113900</td>\n",
       "      <td>9150</td>\n",
       "      <td>101</td>\n",
       "      <td>592</td>\n",
       "      <td>reu site sustainable river remediating invasiv...</td>\n",
       "      <td>-0.081307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1560200</td>\n",
       "      <td>reu site: integrated science for society (is2)</td>\n",
       "      <td>DBI</td>\n",
       "      <td>RSCH EXPER FOR UNDERGRAD SITES, Cross-BIO Acti...</td>\n",
       "      <td>09/15/2016</td>\n",
       "      <td>08/01/2018</td>\n",
       "      <td>Kenneth Burch</td>\n",
       "      <td>MA</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>...</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>this reu site award to boston college locate i...</td>\n",
       "      <td>2016</td>\n",
       "      <td>reu site: integrated science for society (is2)...</td>\n",
       "      <td>113900</td>\n",
       "      <td>8007</td>\n",
       "      <td>101</td>\n",
       "      <td>511</td>\n",
       "      <td>this reu site award to boston college locate i...</td>\n",
       "      <td>-0.066233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1560169</td>\n",
       "      <td>reu site: utilizing plants for innovative rese...</td>\n",
       "      <td>DBI</td>\n",
       "      <td>RSCH EXPER FOR UNDERGRAD SITES</td>\n",
       "      <td>09/15/2016</td>\n",
       "      <td>03/01/2016</td>\n",
       "      <td>Lihua Wang</td>\n",
       "      <td>MI</td>\n",
       "      <td>Kettering University</td>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>...</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>this reu site award to kettering university lo...</td>\n",
       "      <td>2016</td>\n",
       "      <td>reu site: utilizing plants for innovative rese...</td>\n",
       "      <td>113900</td>\n",
       "      <td>9250</td>\n",
       "      <td>101</td>\n",
       "      <td>610</td>\n",
       "      <td>this reu site award to kettering university lo...</td>\n",
       "      <td>-0.114804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1563408</td>\n",
       "      <td>hidden costs of decomposition: the need for fi...</td>\n",
       "      <td>CMMI</td>\n",
       "      <td>EDSE-Engineering Design and Sy, SYS-Systems Sc...</td>\n",
       "      <td>09/01/2016</td>\n",
       "      <td>05/03/2018</td>\n",
       "      <td>Erica Gralla</td>\n",
       "      <td>DC</td>\n",
       "      <td>George Washington University</td>\n",
       "      <td>Standard Grant</td>\n",
       "      <td>...</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>engineered system be become increasingly compl...</td>\n",
       "      <td>2016</td>\n",
       "      <td>hidden costs of decomposition: the need for fi...</td>\n",
       "      <td>072Y00</td>\n",
       "      <td>9251</td>\n",
       "      <td>56</td>\n",
       "      <td>611</td>\n",
       "      <td>engineered system be become increasingly compl...</td>\n",
       "      <td>-0.139214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardNumber                                              Title  \\\n",
       "0      1560196        reu site: earth science on volcanic islands   \n",
       "1      1560048  reu site:  sustainable river (remediating inva...   \n",
       "2      1560200     reu site: integrated science for society (is2)   \n",
       "3      1560169  reu site: utilizing plants for innovative rese...   \n",
       "4      1563408  hidden costs of decomposition: the need for fi...   \n",
       "\n",
       "  NSFOrganization                                         Program(s)  \\\n",
       "0             EAR  EDUCATION AND HUMAN RESOURCES, EDUCATION/HUMAN...   \n",
       "1             DBI  RSCH EXPER FOR UNDERGRAD SITES, EDUCATION AND ...   \n",
       "2             DBI  RSCH EXPER FOR UNDERGRAD SITES, Cross-BIO Acti...   \n",
       "3             DBI                     RSCH EXPER FOR UNDERGRAD SITES   \n",
       "4            CMMI  EDSE-Engineering Design and Sy, SYS-Systems Sc...   \n",
       "\n",
       "    StartDate LastAmendmentDate PrincipalInvestigator State  \\\n",
       "0  10/01/2016        07/17/2018           Paul Wessel    HI   \n",
       "1  09/15/2016        11/19/2017       Meghann Jarchow    SD   \n",
       "2  09/15/2016        08/01/2018         Kenneth Burch    MA   \n",
       "3  09/15/2016        03/01/2016            Lihua Wang    MI   \n",
       "4  09/01/2016        05/03/2018          Erica Gralla    DC   \n",
       "\n",
       "                             Organization   AwardInstrument  ... ARRAAmount  \\\n",
       "0                    University of Hawaii  Continuing Grant  ...      $0.00   \n",
       "1  University of South Dakota Main Campus    Standard Grant  ...      $0.00   \n",
       "2                          Boston College    Standard Grant  ...      $0.00   \n",
       "3                    Kettering University    Standard Grant  ...      $0.00   \n",
       "4            George Washington University    Standard Grant  ...      $0.00   \n",
       "\n",
       "                                            Abstract  Year  \\\n",
       "0  earth science on volcanic island esvi be a new...  2016   \n",
       "1  reu site sustainable river remediating invasiv...  2016   \n",
       "2  this reu site award to boston college locate i...  2016   \n",
       "3  this reu site award to kettering university lo...  2016   \n",
       "4  engineered system be become increasingly compl...  2016   \n",
       "\n",
       "                                                text ProgramElementMain  \\\n",
       "0  reu site: earth science on volcanic islands. e...             157500   \n",
       "1  reu site:  sustainable river (remediating inva...             113900   \n",
       "2  reu site: integrated science for society (is2)...             113900   \n",
       "3  reu site: utilizing plants for innovative rese...             113900   \n",
       "4  hidden costs of decomposition: the need for fi...             072Y00   \n",
       "\n",
       "  ProgramReferenceMain program_label reference_label  \\\n",
       "0                 9150           217             592   \n",
       "1                 9150           101             592   \n",
       "2                 8007           101             511   \n",
       "3                 9250           101             610   \n",
       "4                 9251            56             611   \n",
       "\n",
       "                                          clean_text  Award_scaled  \n",
       "0  earth science on volcanic island esvi be a new...      0.058767  \n",
       "1  reu site sustainable river remediating invasiv...     -0.081307  \n",
       "2  this reu site award to boston college locate i...     -0.066233  \n",
       "3  this reu site award to kettering university lo...     -0.114804  \n",
       "4  engineered system be become increasingly compl...     -0.139214  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awards_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector for covariates\n",
    "covariates = awards_raw[['Year', 'ProgramElementMain', 'ProgramReferenceMain', 'Award_scaled']].copy()\n",
    "\n",
    "# Fill NAs\n",
    "covariates = covariates.fillna(\"unknown\")\n",
    "\n",
    "# One-hot encode\n",
    "covariates_encoded = pd.get_dummies(covariates, columns=['Year', 'ProgramElementMain', 'ProgramReferenceMain', 'Award_scaled'])\n",
    "\n",
    "labels_combined = covariates_encoded.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preprocessed_docs_joined \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m preprocessed_docs]\n",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preprocessed_docs_joined \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m preprocessed_docs]\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "preprocessed_docs_joined = [\" \".join(doc) for doc in preprocessed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextualized_topic_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_preparation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TopicModelDataPreparation\n\u001b[1;32m      3\u001b[0m tp \u001b[38;5;241m=\u001b[39m TopicModelDataPreparation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparaphrase-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# or another SBERT variant\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m training_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mawards_raw\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclean_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# contextual input\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# covariates\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocessed_docs\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# bag-of-words input\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/contextualized_topic_models/utils/data_preparation.py:124\u001b[0m, in \u001b[0;36mTopicModelDataPreparation.fit\u001b[0;34m(self, text_for_contextual, text_for_bow, labels, custom_embeddings)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# TODO: this count vectorizer removes tokens that have len = 1, might be unexpected for the users\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[0;32m--> 124\u001b[0m train_bow_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_for_bow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# if the user is passing custom embeddings we don't need to create the embeddings using the model\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m custom_embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:1376\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1368\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1369\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1370\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1371\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1372\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1373\u001b[0m             )\n\u001b[1;32m   1374\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1376\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1379\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:1263\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1262\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1263\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1264\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1265\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:104\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:62\u001b[0m, in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03mapply to a document.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    preprocessed string\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[0;32m---> 62\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     doc \u001b[38;5;241m=\u001b[39m accent_function(doc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "\n",
    "tp = TopicModelDataPreparation(\"paraphrase-MiniLM-L6-v2\")  # or another SBERT variant\n",
    "\n",
    "training_dataset = tp.fit(\n",
    "    awards_raw['clean_text'].tolist(),  # contextual input\n",
    "    labels_combined,                   # covariates\n",
    "    preprocessed_docs                  # bag-of-words input\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextualized_topic_models.models.ctm import CombinedTM\n",
    "\n",
    "ctm = CombinedTM(\n",
    "    bow_size=len(tp.vocab),\n",
    "    contextual_size=768,\n",
    "    n_components=20,       # you can change this to 10, 30, etc.\n",
    "    num_epochs=30          # higher = more stable, try 30–50\n",
    ")\n",
    "\n",
    "ctm.fit(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ctm.get_topic_lists(10)  # top 10 words per topic\n",
    "\n",
    "for i, topic in enumerate(topics):\n",
    "    print(f\"Topic #{i+1}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc_topic_dist = ctm.get_doc_topic_distribution(training_dataset)\n",
    "\n",
    "topic_df = pd.DataFrame(doc_topic_dist, columns=[f\"Topic_{i}\" for i in range(ctm.n_components)])\n",
    "awards_with_topics = pd.concat([awards_raw.reset_index(drop=True), topic_df], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
